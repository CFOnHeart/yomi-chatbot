"""
å®šä¹‰ä¸»ç®¡Agentï¼Œè´Ÿè´£åè°ƒå’Œç®¡ç†å­Agentã€‚
"""
import json
from typing import List, Dict, Any, Optional

from src.agent.base_agent import AbstractSupervisorAgent, AbstractManagedAgent
from src.config.prompt_manager import get_prompt_manager
from src.config.settings import get_llm_model

class SupervisorAgent(AbstractSupervisorAgent):
    """
    ä¸»ç®¡Agentï¼Œè´Ÿè´£æ¥æ”¶ç”¨æˆ·è¯·æ±‚ï¼Œåˆ†è§£ä»»åŠ¡ï¼Œå¹¶åè°ƒå­Agentæ‰§è¡Œã€‚
    """
    def __init__(self, managed_agents: Optional[List[AbstractManagedAgent]] = None, llm_model=None):
        super().__init__(managed_agents)
        self.prompt_manager = get_prompt_manager()
        self.llm = llm_model or get_llm_model()
        self.task_list = []

    def _generate_agent_descriptions(self) -> str:
        """
        ç”Ÿæˆæ‰€æœ‰å·²æ³¨å†Œå­Agentçš„æè¿°å­—ç¬¦ä¸²ï¼Œç”¨äºPromptã€‚
        """
        if not self.managed_agents:
            return "No managed agents available."
        
        descriptions = []
        for agent in self.managed_agents:
            descriptions.append(f"- Agent Name: {agent.__class__.__name__}\n  Description: {agent.description}")
        return "\n".join(descriptions)

    def invoke(self, query: str, context: Optional[Dict[str, Any]] = None) -> Any:
        """
        æ‰§è¡Œä¸»ç®¡Agentçš„æ ¸å¿ƒé€»è¾‘ã€‚

        1. åˆ†è§£ä»»åŠ¡ã€‚
        2. å¾ªç¯æ‰§è¡Œä»»åŠ¡ï¼Œç›´åˆ°æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚
        3. åœ¨æ¯ä¸€æ­¥ä¸­ï¼Œé€‰æ‹©åˆé€‚çš„Agentæˆ–è‡ªå·±æ‰§è¡Œã€‚
        4. æ±‡æ€»ç»“æœå¹¶è¿”å›ã€‚
        """
        print(f"ğŸ¤– Supervisor Agent received query: {query}")

        # 1. åˆ†è§£ä»»åŠ¡
        plan_prompt = self.prompt_manager.populate_template(
            self.prompt_manager.RAG_PROMPT_PATH,
            "supervisor_plan", 
            {"user_query": query}
        )
        
        print("ğŸ¤” Supervisor is thinking about the plan...")
        plan_response = self.llm.invoke(plan_prompt)
        
        # å¤„ç†LLMå“åº”æ ¼å¼
        if hasattr(plan_response, 'content'):
            plan_response_text = plan_response.content
        else:
            plan_response_text = str(plan_response)
        
        try:
            # å‡è®¾æ¨¡å‹è¿”å›ä¸€ä¸ªJSONå­—ç¬¦ä¸²ï¼Œå…¶ä¸­åŒ…å«ä»»åŠ¡åˆ—è¡¨
            self.task_list = json.loads(plan_response_text).get("tasks", [])
            print(f"ğŸ“ Supervisor's Plan: {self.task_list}")
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°†æ•´ä¸ªå“åº”ä½œä¸ºä¸€ä¸ªä»»åŠ¡
            self.task_list = [plan_response_text]
            print(f"ğŸ“ Supervisor's Plan (fallback): {self.task_list}")

        # 2. å¾ªç¯æ‰§è¡Œä»»åŠ¡
        results = []
        full_context = context.get("chat_history", "") if context else ""

        while self.task_list:
            current_task = self.task_list.pop(0)
            print(f"\nğŸš€ Executing task: {current_task}")
            
            agent_descriptions = self._generate_agent_descriptions()
            
            # 3. é€‰æ‹©Agent
            delegation_prompt = self.prompt_manager.populate_template(
                self.prompt_manager.RAG_PROMPT_PATH,
                "supervisor_delegate",
                {
                    "task": current_task,
                    "agents": agent_descriptions,
                    "context": full_context
                }
            )
            
            print("ğŸ¤” Supervisor is deciding who should handle this...")
            delegation_response = self.llm.invoke(delegation_prompt)
            
            # å¤„ç†LLMå“åº”æ ¼å¼
            if hasattr(delegation_response, 'content'):
                delegation_response_text = delegation_response.content
            else:
                delegation_response_text = str(delegation_response)
            
            try:
                delegation_decision = json.loads(delegation_response_text)
                agent_name = delegation_decision.get("agent_name")
                sub_task_query = delegation_decision.get("task_input")
            except json.JSONDecodeError:
                agent_name = "SupervisorAgent" # è§£æå¤±è´¥åˆ™è‡ªå·±å¤„ç†
                sub_task_query = current_task

            # 4. æ‰§è¡Œä»»åŠ¡
            task_result = ""
            selected_agent = self.get_agent(agent_name) if agent_name else None

            if selected_agent:
                print(f"Delegating to {agent_name}...")
                task_result = selected_agent.invoke(sub_task_query, context={"chat_history": full_context})
            else:
                print("No suitable agent found, Supervisor is handling it.")
                # å¦‚æœæ²¡æœ‰åˆé€‚çš„å­Agentï¼ŒSupervisorè‡ªå·±å¤„ç†
                # è¿™é‡Œå¯ä»¥è°ƒç”¨ä¸€ä¸ªåŸºç¡€çš„LLMæ¥å®Œæˆä»»åŠ¡
                self_execution_prompt = self.prompt_manager.populate_template(
                    self.prompt_manager.RAG_PROMPT_PATH,
                    "supervisor_self_execute",
                    {
                        "task": current_task,
                        "context": full_context
                    }
                )
                task_result = self.llm.invoke(self_execution_prompt)
                
                # å¤„ç†LLMå“åº”æ ¼å¼
                if hasattr(task_result, 'content'):
                    task_result = task_result.content

            print(f"âœ… Task finished, result: {task_result[:150]}...")
            results.append(task_result)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            full_context += f"\n\nPrevious Task Result:\n{task_result}"
            if self.task_list:
                full_context += f"\n\nNext Task:\n{self.task_list[0]}"

        # 5. æ±‡æ€»ç»“æœ
        summary_prompt = self.prompt_manager.populate_template(
            self.prompt_manager.RAG_PROMPT_PATH,
            "supervisor_summarize",
            {
                "user_query": query,
                "results": "\n---\n".join(results)
            }
        )
        
        print("ğŸ“ Supervisor is summarizing the final answer...")
        final_answer = self.llm.invoke(summary_prompt)
        
        # å¤„ç†LLMå“åº”æ ¼å¼
        if hasattr(final_answer, 'content'):
            final_answer = final_answer.content
            
        print("ğŸ‰ Supervisor finished.")
        
        return final_answer
