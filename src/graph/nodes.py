from langchain_core.messages import HumanMessage, AIMessage
from src.graph.state import AgentState, ToolExecutionResult, RAGSearchResult
from src.memory.smart_memory_manager import SmartMemoryManager
from src.tools.tool_manager import ToolConfirmationSystem
from src.model.azure_openai_model import get_azure_openai_model
from src.database.chat_db import ChatDatabase
from src.rag.rag_system import RAGSystem

class AgentNodes:
    """Agentå·¥ä½œæµèŠ‚ç‚¹"""
    
    def __init__(self):
        self.db = ChatDatabase()
        self.memory_manager = SmartMemoryManager(self.db)
        self.tool_system = ToolConfirmationSystem()
        self.llm = get_azure_openai_model()
        self.rag_system = RAGSystem()
    
    def initialize_session_node(self, state: AgentState) -> AgentState:
        """åˆå§‹åŒ–ä¼šè¯èŠ‚ç‚¹"""
        session_id = state["session_id"]
        
        # åˆå§‹åŒ–ä¼šè¯
        success = self.memory_manager.initialize_session(session_id)
        
        if not success:
            state["error_message"] = f"ä¼šè¯ {session_id} åˆå§‹åŒ–å¤±è´¥"
            return state
        
        # è·å–ä¼šè¯å†å²
        history = self.memory_manager.get_session_history(session_id)
        state["messages"] = history.messages.copy()
        
        print(f"âœ… ä¼šè¯ {session_id} åˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½äº† {len(state['messages'])} æ¡å†å²è®°å½•")
        
        return state
    
    def save_user_input_node(self, state: AgentState) -> AgentState:
        """ä¿å­˜ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹"""
        session_id = state["session_id"]
        user_input = state["user_input"]
        
        # ä¿å­˜ç”¨æˆ·è¾“å…¥åˆ°æ•°æ®åº“
        self.memory_manager.add_user_message(session_id, user_input)
        
        # æ›´æ–°çŠ¶æ€ä¸­çš„æ¶ˆæ¯
        state["messages"].append(HumanMessage(content=user_input))
        
        print(f"ğŸ’¾ ç”¨æˆ·è¾“å…¥å·²ä¿å­˜: {user_input[:50]}...")
        
        return state
    
    def tool_detection_node(self, state: AgentState) -> AgentState:
        """å·¥å…·æ£€æµ‹èŠ‚ç‚¹"""
        user_input = state["user_input"]
        
        # æ£€æµ‹æ˜¯å¦éœ€è¦å·¥å…·
        detection_result = self.tool_system.tool_matcher.detect_tool_need(user_input)
        
        state["tool_detection_result"] = detection_result
        state["needs_tool"] = detection_result.get("needs_tool", False)
        
        if state["needs_tool"]:
            print(f"ğŸ”§ æ£€æµ‹åˆ°éœ€è¦å·¥å…·: {detection_result.get('tool_name', 'unknown')}")
            print(f"ğŸ¯ ç½®ä¿¡åº¦: {detection_result.get('confidence', 0.0):.2f}")
        else:
            print(f"ğŸ’­ æ— éœ€å·¥å…·ï¼Œç›´æ¥LLMå›ç­”")
        
        return state
    
    def tool_execution_node(self, state: AgentState) -> AgentState:
        """å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹"""
        detection_result = state["tool_detection_result"]
        tool_name = detection_result.get("tool_name")
        suggested_args = detection_result.get("suggested_args", {})
        confidence = detection_result.get("confidence", 0.0)
        
        # æ£€æŸ¥ç½®ä¿¡åº¦
        if confidence < 0.7:
            print(f"âš ï¸ å·¥å…·æ£€æµ‹ç½®ä¿¡åº¦è¿‡ä½ ({confidence:.2f})ï¼Œè·³è¿‡å·¥å…·æ‰§è¡Œ")
            state["needs_tool"] = False
            return state
        
        # æ˜¾ç¤ºå·¥å…·ä¿¡æ¯å¹¶ç¡®è®¤
        tool_schema = self.tool_system.tool_matcher.get_tool_schema(tool_name)
        if not tool_schema:
            print(f"âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
            state["needs_tool"] = False
            return state
        
        # ç¡®è®¤å·¥å…·æ‰§è¡Œ
        if self.tool_system.confirm_tool_execution(tool_name, suggested_args):
            # æ‰§è¡Œå·¥å…·
            success, result = self.tool_system.execute_tool(tool_name, suggested_args)
            
            # åˆ›å»ºå·¥å…·æ‰§è¡Œç»“æœ
            tool_result = ToolExecutionResult(
                success=success,
                tool_name=tool_name,
                tool_args=suggested_args,
                result=result,
                confidence=confidence
            )
            
            state["tool_execution_result"] = tool_result
            
            if success:
                print(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ: {result}")
                
                # ä¿å­˜å·¥å…·æ‰§è¡Œç»“æœåˆ°æ•°æ®åº“
                self.memory_manager.add_tool_message(
                    state["session_id"],
                    result,
                    tool_name,
                    suggested_args
                )
                
                # è®¾ç½®æœ€ç»ˆå“åº”
                state["final_response"] = f"å·¥å…·æ‰§è¡Œç»“æœ: {result}"
                
            else:
                print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {result}")
                state["error_message"] = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {result}"
                state["needs_tool"] = False
        else:
            print("âŒ ç”¨æˆ·å–æ¶ˆå·¥å…·æ‰§è¡Œ")
            state["needs_tool"] = False
        
        return state
    
    def llm_response_node(self, state: AgentState) -> AgentState:
        """LLMå“åº”èŠ‚ç‚¹"""
        session_id = state["session_id"]
        messages = state["messages"].copy()
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰RAGä¸Šä¸‹æ–‡
            rag_result = state.get("rag_search_result")
            if rag_result and rag_result.has_relevant_docs:
                # å°†RAGä¸Šä¸‹æ–‡æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                context_message = HumanMessage(content=rag_result.context_for_llm)
                messages.insert(-1, context_message)  # åœ¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰æ’å…¥
                
                print(f"ğŸ“– ä½¿ç”¨RAGä¸Šä¸‹æ–‡ç”Ÿæˆå“åº”")
            else:
                print(f"ğŸ¤– ç›´æ¥ä½¿ç”¨LLMç”Ÿæˆå“åº”")
            
            # è·å–LLMå“åº”
            response = self.llm.invoke(messages)
            ai_response = response.content
            
            # å¦‚æœä½¿ç”¨äº†RAGï¼Œæ·»åŠ å¼•ç”¨ä¿¡æ¯
            if rag_result and rag_result.has_relevant_docs:
                ai_response += rag_result.source_references
            
            # ä¿å­˜AIå“åº”
            self.memory_manager.add_ai_message(session_id, ai_response)
            
            # æ›´æ–°çŠ¶æ€
            state["messages"].append(AIMessage(content=ai_response))
            state["final_response"] = ai_response
            
            print(f"ğŸ¤– LLMå“åº”: {ai_response[:100]}...")
            
        except Exception as e:
            error_msg = f"LLMå“åº”å¤±è´¥: {str(e)}"
            state["error_message"] = error_msg
            state["final_response"] = "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
            print(f"âŒ {error_msg}")
        
        return state
    
    def finalize_response_node(self, state: AgentState) -> AgentState:
        """æœ€ç»ˆå“åº”èŠ‚ç‚¹"""
        session_id = state["session_id"]
        
        # å¢åŠ æ­¥éª¤è®¡æ•°
        state["step_count"] = state.get("step_count", 0) + 1
        
        # æ˜¾ç¤ºä¼šè¯ä¿¡æ¯
        session_info = self.memory_manager.get_session_info(session_id)
        if session_info:
            print(f"\nğŸ“Š ä¼šè¯ç»Ÿè®¡:")
            print(f"   â€¢ æ¶ˆæ¯æ•°é‡: {session_info['message_count']}")
            print(f"   â€¢ æ–‡æœ¬é•¿åº¦: {session_info['text_length']}")
            print(f"   â€¢ éœ€è¦æ‘˜è¦: {'æ˜¯' if session_info['needs_summary'] else 'å¦'}")
        
        print(f"\nğŸ¯ æœ€ç»ˆå“åº”: {state['final_response']}")
        
        return state
    
    def rag_search_node(self, state: AgentState) -> AgentState:
        """RAGæœç´¢èŠ‚ç‚¹"""
        user_input = state["user_input"]
        session_id = state["session_id"]
        
        print(f"ğŸ” æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£...")
        
        try:
            # æœç´¢ç›¸å…³æ–‡æ¡£
            documents = self.rag_system.search_relevant_documents(
                query=user_input,
                top_k=5,
                session_id=session_id
            )
            
            # ç”ŸæˆLLMä¸Šä¸‹æ–‡
            context_for_llm = self.rag_system.format_context_for_llm(documents)
            
            # ç”Ÿæˆå¼•ç”¨ä¿¡æ¯
            source_references = self.rag_system.format_source_references(documents)
            
            # åˆ›å»ºRAGæœç´¢ç»“æœ
            rag_result = RAGSearchResult(
                has_relevant_docs=len(documents) > 0,
                documents=documents,
                context_for_llm=context_for_llm,
                source_references=source_references,
                search_query=user_input
            )
            
            state["rag_search_result"] = rag_result
            
            if documents:
                print(f"ğŸ“š æ‰¾åˆ° {len(documents)} ä¸ªç›¸å…³æ–‡æ¡£")
                for i, doc in enumerate(documents, 1):
                    print(f"   {i}. {doc.title} (ç›¸ä¼¼åº¦: {doc.similarity_score:.2f})")
                    if doc.file_path:
                        print(f"      ğŸ“ {doc.file_path}")
                    if doc.start_line > 0:
                        print(f"      ğŸ“ ç¬¬ {doc.start_line}-{doc.end_line} è¡Œ")
            else:
                print(f"ğŸ“ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œå°†ç›´æ¥ä½¿ç”¨LLMå›ç­”")
            
        except Exception as e:
            error_msg = f"RAGæœç´¢å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            state["error_message"] = error_msg
            
            # è®¾ç½®ç©ºçš„RAGç»“æœ
            state["rag_search_result"] = RAGSearchResult(
                has_relevant_docs=False,
                documents=[],
                context_for_llm="",
                source_references="",
                search_query=user_input
            )
        
        return state
    
    def error_handling_node(self, state: AgentState) -> AgentState:
        """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
        error_msg = state.get("error_message", "æœªçŸ¥é”™è¯¯")
        
        # è®°å½•é”™è¯¯
        print(f"âŒ å¤„ç†é”™è¯¯: {error_msg}")
        
        # è®¾ç½®é”™è¯¯å“åº”
        state["final_response"] = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜: {error_msg}"
        
        return state
